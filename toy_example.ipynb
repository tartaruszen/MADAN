{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load cython functions\n",
      "No module named '_cython_fast_funcs'\n"
     ]
    }
   ],
   "source": [
    "from pygsp import graphs, filters, plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from Plotters import *\n",
    "from Nets import *\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "from ipywidgets import *\n",
    "from functions import *\n",
    "from sklearn import preprocessing, metrics\n",
    "import community\n",
    "from LouvainClustering_fast import Clustering\n",
    "from LouvainClustering_fast import norm_var_information\n",
    "plt.rcParams['image.cmap'] = 'jet'\n",
    "pl = Plotters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------\n",
    "# Run All Cells\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "num_net     =    2\n",
    "name        =   'toy_example'\n",
    "attributes  =   ['income']\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# Loading network\n",
    "#------------------------------------------------------------------------\n",
    "data        =   Nets(num_net,attributes[0]) \n",
    "net         =   data.net\n",
    "N           =   net.order()\n",
    "partition   =   nx.get_node_attributes(net,\"block\")\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# Getting grund truth\n",
    "#------------------------------------------------------------------------\n",
    "y_true      =   [net.node[n]['anomaly'] for n in net.nodes()] \n",
    "true_nodes  =   [i for i in range(0,len(y_true)) if y_true[i]==1]\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# Setting Markov times\n",
    "#------------------------------------------------------------------------\n",
    "time        =   10**np.linspace(0,5,2000)\n",
    "time        =   np.concatenate([np.array([0]),time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-05 10:19:48,611:[INFO](pygsp.graphs.community.__init__): Constructed using eps-NN with eps = 2.514866859365871\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------\n",
    "# Setting layout for plotting the network\n",
    "#------------------------------------------------------------------------\n",
    "G = graphs.Community(N=160, Nc=4, comm_sizes=[30, 70, 35, 25] , seed=42)\n",
    "G.set_coordinates(kind='community2D')\n",
    "corrd = G.coords\n",
    "#------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------\n",
    "# Defining matrix of node attributes\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "f_matrix = np.zeros((N,len(attributes)))\n",
    "for i, att in enumerate(attributes):\n",
    "    attribs =  nx.get_node_attributes(net,att)\n",
    "    f_matrix[:,i] =  list(attribs.values())\n",
    "\n",
    "\n",
    "f_scaled  =  preprocessing.MinMaxScaler().fit_transform(f_matrix)\n",
    "f  = np.matrix(f_scaled[:,0]).reshape(N,1)\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "A     = nx.adjacency_matrix(net).toarray()\n",
    "sigma = 0.08\n",
    "W     = get_weigth_matrix_vectors(A,f_scaled,sigma)\n",
    "\n",
    "G = graphs.Graph(W)\n",
    "\n",
    "G.compute_fourier_basis() \n",
    "G.set_coordinates(corrd)\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# Random walk components\n",
    "#------------------------------------------------------------------------\n",
    "v_ones      =  np.matrix(np.ones((N,1)))\n",
    "degree_vect =  W.sum(axis=1)                        # strengths vector\n",
    "D           =  np.matrix(np.diag(degree_vect))    \n",
    "avg_d       =  (v_ones.T*D*v_ones)[0,0]/N           # average strength\n",
    "\n",
    "# stationary distribution\n",
    "pi          =  v_ones.A.T.reshape(N)/N\n",
    "#------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------\n",
    "# Plotting the concentration of energy on the network, the clusters found by Louvain algorithm when \n",
    "# evaluating the Markov stability at the same time than the filtering process, and the bars of concentration + threshold of anomalousness\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "def plot_heat(t=0):\n",
    "    \n",
    "    #------------------------------------------------------------------------\n",
    "    # Computing Fourier basis evaluated at t\n",
    "    #------------------------------------------------------------------------\n",
    "    tau = time[int(t)]\n",
    "            \n",
    "    kernel     =  np.exp(-tau/avg_d*(G.e/G.lmax)) \n",
    "    exp_sigma  =  np.diag(kernel)\n",
    "    Ht         =  np.dot(np.dot(G.U,exp_sigma),G.U.T)\n",
    "    #------------------------------------------------------------------------\n",
    "    \n",
    "    print(\"Markov time: \",tau/G.lmax);print(\"\\n\");\n",
    "    #------------------------------------------------------------------------\n",
    "    # Plot Concentration \n",
    "    #------------------------------------------------------------------------\n",
    "    fig, axes  =  plt.subplots(1, 2); \n",
    "    concent    =  np.linalg.norm(Ht, axis=0, ord=2)\n",
    "       \n",
    "    m_concent  =  np.matrix(concent.reshape(N,1))\n",
    "    print(\"Global smoothness of concentration: \", m_concent.T*G.L.todense()*m_concent)\n",
    "    pl.visualize_graph_signal(G,concent,title='t='+str(tau), ax=axes[0]) \n",
    "    axes[1]    = plt.imshow(W,interpolation='None')\n",
    "    #cbar     = plt.colorbar(ax=axes[1])\n",
    "    plt.title('W')\n",
    "    plt.grid(False)        \n",
    "    plt.show()\n",
    "   #------------------------------------------------------------------------\n",
    "\n",
    "    #------------------------------------------------------------------------\n",
    "    #  Find clusters with Louvain algorithm and plot them\n",
    "    #------------------------------------------------------------------------\n",
    "    \n",
    "    clustering        =  Clustering(p1=pi, p2=pi, T=Ht)    \n",
    "    clustering.find_louvain_clustering(rnd_seed=3)\n",
    "    clust_labels      =  np.array(list(clustering.partition.node_to_cluster_dict.values()))\n",
    "    \n",
    "    interp_com        =  interpolate_comm2(net,clust_labels, true_nodes)\n",
    "    print(\"Num of clusters: \",len(set(interp_com)))\n",
    "\n",
    "    node_labels = dict(zip(net.nodes(), np.array(interp_com, dtype='int')))\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2);    \n",
    "    pl.visualize_graph_signal(G,interp_com,ax=axes[0], node_labels=node_labels)\n",
    "    axes[1]   = plt.imshow(Ht,interpolation='None')\n",
    "    plt.title('T = g_t(L)')\n",
    "    plt.grid(False)  \n",
    "    plt.show() \n",
    "    #------------------------------------------------------------------------\n",
    "    \n",
    "    #------------------------------------------------------------------------\n",
    "    # Plotting concentration\n",
    "    #------------------------------------------------------------------------\n",
    "    comm_concent = np.zeros((N,2))\n",
    "    comm_concent[:,0] = interp_com\n",
    "    comm_concent[:,1] = concent\n",
    "    \n",
    "    df_comm_concent   = pd.DataFrame(comm_concent, columns=['groups','concentration'])\n",
    "    \n",
    "    ax = plt.subplot(1, 1, 1)\n",
    "    std_val = df_comm_concent['concentration'].std()\n",
    "\n",
    "    df_comm_concent.plot(kind='bar', title='Node concentration', grid=False, y='concentration',rot=0, ax=ax, cmap='viridis', fontsize=8, legend=False)\n",
    "    plt.hlines(df_comm_concent['concentration'].mean() + 2.0*std_val, xmin=-1, xmax=170, linestyles='dashed', alpha=1.0, color='blue')\n",
    "    ax.set_facecolor((1.0, 1.0, 1.0))\n",
    "\n",
    "    return (interp_com, concent)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "392011a579e94d9a8c89b810c1d617d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='0', continuous_update=False, description='t'), Output()), _dom_classes=('wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mpl.rcParams['figure.figsize'] = 18, 6\n",
    "\n",
    "a = widgets.Text(value='0', continuous_update=False)\n",
    "res_interact = interactive(plot_heat, t=a)\n",
    "display(res_interact)\n",
    "\n",
    "# Try:\n",
    "#t = 682\n",
    "#t = 1020\n",
    "#t = 1715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'\\nmat_voi    =  np.zeros((len(time),len(time)))\\n\\nmat_parts  = []    \\nfor t in range(len(time)):\\n    \\n    kernel     =  np.exp(-time[t]/avg_d*(G.e/G.lmax)) \\n    exp_sigma  =  np.diag(kernel)\\n    Ht         =  np.dot(np.dot(G.U,exp_sigma),G.U.T)\\n    clustering        =  Clustering(p1=pi, p2=pi, T=Ht)  \\n    clustering.find_louvain_clustering(rnd_seed=3)\\n    mat_parts.append(np.array(list(clustering.partition.node_to_cluster_dict.values())))\\n\\nmat_parts = np.array(mat_parts)\\nnp.savetxt('variation_of_information/toy_example_partitions.csv', mat_parts.T, fmt='%d')\\nnp.savetxt('variation_of_information/toy_example_time.csv', time/G.lmax, fmt='%.4f')\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------\n",
    "# Compute optimal partitions for each t. That will be used to compute the variation of information.\n",
    "#--------------------------------------------------------------------------\n",
    "''''\n",
    "mat_voi    =  np.zeros((len(time),len(time)))\n",
    "\n",
    "mat_parts  = []    \n",
    "for t in range(len(time)):\n",
    "    \n",
    "    kernel     =  np.exp(-time[t]/avg_d*(G.e/G.lmax)) \n",
    "    exp_sigma  =  np.diag(kernel)\n",
    "    Ht         =  np.dot(np.dot(G.U,exp_sigma),G.U.T)\n",
    "    clustering        =  Clustering(p1=pi, p2=pi, T=Ht)  \n",
    "    clustering.find_louvain_clustering(rnd_seed=3)\n",
    "    mat_parts.append(np.array(list(clustering.partition.node_to_cluster_dict.values())))\n",
    "\n",
    "mat_parts = np.array(mat_parts)\n",
    "np.savetxt('variation_of_information/toy_example_partitions.csv', mat_parts.T, fmt='%d')\n",
    "np.savetxt('variation_of_information/toy_example_time.csv', time/G.lmax, fmt='%.4f')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
